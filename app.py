import streamlit as st
import pandas as pd
import plotly.express as px
import datetime

# === CONFIGURATION DE LA PAGE ===
st.set_page_config(page_title="üìä Tableau de Bord Web Analytics", layout="wide")

# === CHARGEMENT DES DONN√âES ===
@st.cache_data
def load_data():
    file_path = "owa_action_fact2.csv"
    df = pd.read_csv(file_path, parse_dates=["timestamp"])

    # Nettoyer les noms de colonnes (√©vite les erreurs de KeyError)
    df.columns = df.columns.str.strip()

    return df

df = load_data()

# V√©rification de l'existence de "source_name"
if "source_name" not in df.columns:
    st.error("üö® Erreur : La colonne 'source_name' n'existe pas dans le fichier.")
    st.stop()

# === SIDEBAR (FILTRES DYNAMIQUES) ===
st.sidebar.header("üîç Filtres")

# üóì S√©lection d‚Äôune p√©riode avec un calendrier
min_date = df["timestamp"].min().date()
max_date = df["timestamp"].max().date()
start_date, end_date = st.sidebar.date_input("üìÜ S√©lectionner une p√©riode :", [min_date, max_date], min_value=min_date, max_value=max_date)

# Filtrer les donn√©es en fonction des dates s√©lectionn√©es
filtered_df = df[(df["timestamp"].dt.date >= start_date) & (df["timestamp"].dt.date <= end_date)]

# üîó S√©lection des canaux d‚Äôacquisition
medium_selected = st.sidebar.multiselect("üõí Canal d'acquisition", df["medium"].unique(), default=df["medium"].unique())

# üîó S√©lection des sources (affichage des noms des sources)
source_selected = st.sidebar.multiselect("üîó Source", df["source_name"].dropna().unique(), default=df["source_name"].dropna().unique())

# üë• Type de visiteur
visitor_type = st.sidebar.radio("üë• Type de visiteur", ["Tous", "Nouveau", "R√©current"])

# Appliquer les autres filtres
filtered_df = filtered_df[
    (filtered_df["medium"].isin(medium_selected)) &
    (filtered_df["source_name"].isin(source_selected))
]

if visitor_type == "Nouveau":
    filtered_df = filtered_df[filtered_df["is_new_visitor"] == 1]
elif visitor_type == "R√©current":
    filtered_df = filtered_df[filtered_df["is_repeat_visitor"] == 1]

# === SCORE D'ENGAGEMENT ===
# üõ† Correction : Assurer que "last_req" et "timestamp" sont bien en datetime
df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")

if df["last_req"].dtype != 'datetime64[ns]':
    df["last_req"] = pd.to_numeric(df["last_req"], errors="coerce")  # Convertir en nombre si n√©cessaire
    df["last_req"] = pd.to_datetime(df["last_req"], unit="s", errors="coerce")  # Convertir en datetime

# V√©rifier si les conversions ont bien fonctionn√©
if df["last_req"].isna().sum() > 0:
    st.warning("‚ö† Certaines valeurs de 'last_req' n'ont pas pu √™tre converties en datetime.")

# V√©rifier les types de donn√©es avant conversion
st.write("Avant conversion :")
st.write(df.dtypes)

# ‚úÖ Correction : Assurer que "timestamp" est bien en datetime
if not pd.api.types.is_datetime64_any_dtype(df["timestamp"]):
    df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")

# ‚úÖ Correction : Assurer que "last_req" est bien en datetime
if not pd.api.types.is_datetime64_any_dtype(df["last_req"]):
    df["last_req"] = pd.to_numeric(df["last_req"], errors="coerce")  # Convertir en nombre si n√©cessaire
    df["last_req"] = pd.to_datetime(df["last_req"], unit="s", errors="coerce")  # Convertir en datetime

# üîç V√©rifier s'il y a encore des NaN apr√®s conversion
st.write("Apr√®s conversion :")
st.write(df.dtypes)

# V√©rifier les valeurs incorrectes avant la soustraction
if df["last_req"].isna().sum() > 0 or df["timestamp"].isna().sum() > 0:
    st.warning("‚ö† Certaines valeurs n'ont pas pu √™tre converties en datetime !")
    st.write(df[df["last_req"].isna() | df["timestamp"].isna()])

# ‚úÖ Correction de la soustraction
df["session_duration"] = (df["last_req"] - df["timestamp"]).dt.total_seconds()
df["session_duration"] = df["session_duration"].fillna(0)  # Remplacer NaN par 0

# ‚úÖ Correction appliqu√©e aussi au `filtered_df`
filtered_df["session_duration"] = (filtered_df["last_req"] - filtered_df["timestamp"]).dt.total_seconds()
filtered_df["session_duration"] = filtered_df["session_duration"].fillna(0)

# Calcul de la dur√©e de session en secondes
df["session_duration"] = (df["last_req"] - df["timestamp"]).dt.total_seconds().fillna(0)

# Appliquer la correction au dataframe filtr√©
filtered_df["session_duration"] = (filtered_df["last_req"] - filtered_df["timestamp"]).dt.total_seconds().fillna(0)

action_weights = {
    'frontend submit': 5,
    'frontend modify': 3,
    'editor publish': 7,
    'frontend create': 8,
    'view': 2  # Exemple de poids augment√©s
}
filtered_df['action_score'] = filtered_df['action_name'].map(action_weights).fillna(1)
filtered_df['group_score'] = filtered_df['action_group'].apply(lambda x: 4 if x == 'publish' else 2)

# Agr√©gation des donn√©es par visiteur
df_grouped = filtered_df.groupby('visitor_id').agg(
    num_sessions=('session_id', 'nunique'),
    repeat_visitor=('is_repeat_visitor', 'max'),
    new_visitor=('is_new_visitor', 'max'),
    total_numeric_value=('numeric_value', 'sum'),
    avg_days_since_prior_session=('days_since_prior_session', 'mean'),
    avg_days_since_first_session=('days_since_first_session', 'mean'),
    total_session_duration=('session_duration', 'sum'),
    total_action_score=('action_score', 'sum'),
    total_group_score=('group_score', 'sum'),
    unique_actions=('action_name', 'nunique'),
    unique_groups=('action_group', 'nunique')
).reset_index()

# S'assurer que certaines valeurs restent positives
df_grouped['avg_days_since_first_session'] = df_grouped['avg_days_since_first_session'].apply(lambda x: max(x, 1))
df_grouped['total_session_duration'] = df_grouped['total_session_duration'].apply(lambda x: max(x, 1))

# Normalisation du score d'implication
df_grouped['engagement_score'] = (
    df_grouped['num_sessions'] * 5 +
    df_grouped['repeat_visitor'] * 6 - df_grouped['new_visitor'] * 2 +
    df_grouped['total_numeric_value'] * 3 +
    (30 / (df_grouped['avg_days_since_prior_session'] + 1)) +
    (50 / (df_grouped['avg_days_since_first_session'] + 1)) +
    (df_grouped['total_session_duration'] / 30) +
    df_grouped['total_action_score'] * 2 +
    df_grouped['total_group_score'] * 3 +
    df_grouped['unique_actions'] * 4 +
    df_grouped['unique_groups'] * 5
)

# Mise √† l'√©chelle entre 0 et 100
df_grouped['engagement_score'] = (df_grouped['engagement_score'] - df_grouped['engagement_score'].min()) / (
    df_grouped['engagement_score'].max() - df_grouped['engagement_score'].min()) * 100

# Supprimer les utilisateurs avec un score d'implication de 0
df_grouped = df_grouped[df_grouped['engagement_score'] > 0]

# Streamlit App
st.title("Tableau de Bord d'Implication des Visiteurs")

st.subheader("Scatter Plot : Score d'Implication des Visiteurs")

# ‚úÖ Correction : Convertir visitor_id en cha√Æne de caract√®res pour une meilleure lisibilit√©
df_grouped['visitor_id'] = df_grouped['visitor_id'].astype(str)

# ‚úÖ Correction : Ajustement dynamique de l'axe Y
fig = px.scatter(df_grouped, x='visitor_id', y='engagement_score',
                 color='engagement_score',
                 size='engagement_score',
                 hover_data=['num_sessions', 'total_action_score', 'total_group_score'],
                 title="Engagement Score des Visiteurs",
                 color_continuous_scale="Blues")

fig.update_layout(yaxis=dict(range=[df_grouped['engagement_score'].min(), df_grouped['engagement_score'].max()]))

st.plotly_chart(fig)

st.subheader("Donn√©es Agr√©g√©es par Visiteur")
st.dataframe(df_grouped)

st.markdown("---")
st.markdown("üöÄ **Tableau de bord optimis√© pour l‚Äôanalyse de performances marketing web**")
